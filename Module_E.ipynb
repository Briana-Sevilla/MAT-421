{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP897uvxe+UUJwRSA4G8RSk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Briana-Sevilla/MAT-421/blob/main/Module_E.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Homework Set 6: Module E**"
      ],
      "metadata": {
        "id": "pVrN73OYqI2n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Section 3.2: Continuity and Differentiation"
      ],
      "metadata": {
        "id": "JGoq_5zTRRNu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.2.1: Limits and Continuity"
      ],
      "metadata": {
        "id": "OkDZYZYruse6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Euclidean norm is used such that\n",
        "\n",
        "$||x‚Éó||=\\sqrt{\\sum_{i=1}^dx_i^2}$\n",
        "\n",
        "where:\n",
        "- $x‚Éó = (x_1,...,x_d)^T$\n",
        "\n",
        "The open $r$-ball around $x \\in ‚Ñù^d$ is the set of points within the Euclidean distance radius, $r$ ($x$ is the origin). This can be represented by the following:\n",
        "\n",
        "$B_r(x)=\\{y \\in ‚Ñù^d: ||y-x||< r\\}$\n",
        "\n",
        "$x$ is a limit point of a set, $A$, if all the open balls around $x$ have one element, $a$ of $A$ in their circle that is not $x$ ($a\\neq x$). If every open ball does not contain one element, $x$ is not a limit point.\n",
        "\n",
        "Every limit point of a closed set $A$ belongs to $A$. On the other hand, an open set has the following property:\n",
        "\n",
        "$B_r(x) ‚äÜ A$ for all $x \\in A$\n",
        "\n",
        "The **Limit of a Function** can be represented by:\n",
        "\n",
        "$\\lim\\limits_{x \\to a} f(x)=L $\n",
        "\n",
        "where:\n",
        "- $f: D \\to ‚Ñù $ is a real-valued function on $D‚äÜ ‚Ñù^d$\n",
        "- $L \\in ‚Ñù$\n",
        "\n",
        "A fucntion is **continuous** if its value does not change abruptly (no breaks or jumps). If the function introduced above is continuous, it can be expressed the following way:\n",
        "\n",
        "$\\lim\\limits_{x \\to a}f(x)=f(a)$\n",
        "\n",
        "where $a \\in D$\n",
        "\n",
        "Composition function $g‚àòf$ or $g(f(x))$ is continuous at $x_0$ if $f$ is continuous at $x_0$ and if $g$ is continuous on $f(x_0)$.\n",
        "\n",
        "**Max**: largest value in $f(x)$.\n",
        "\n",
        "**Min**: smallest value in $f(x)$.\n",
        "\n",
        "**Extreme Value**: values that are either the maximum or minimum."
      ],
      "metadata": {
        "id": "vgoFOCQZww_b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.2.2: Derivatives"
      ],
      "metadata": {
        "id": "AbXge7uYCrMa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3.2.2.1: Single-Variable Case"
      ],
      "metadata": {
        "id": "64-weVM7CwbC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Derivative**: measures the rate of change of a function's output value in respect to another variable. This can be represented by the following:\n",
        "\n",
        "$f'(x_0) = \\frac{df(x_0)}{dx}=\\lim\\limits_{h \\to 0}\\frac{f(x_0+h)-f(x_0)}{h}$ (if the limit exists)\n",
        "\n",
        "A derivative is most commonly known as the slope of a line (rise over run, which is a rate of change). Derivatives can also help us find extreme values:\n",
        "\n",
        "$f'(x)=0$ (solve for x. The solution(s) tell us when we have an extreme value)\n",
        "\n",
        "Here is an example of how to find the derivative of a function:\n",
        "\n",
        "$g'(x) = (x^2+5x+1)\\frac{d}{dx}= 2x+5+0=2x+5$\n",
        "\n",
        "To find the derivative at a specific $x$, just plug it into $2x+5$.\n",
        "\n",
        "Example of how to find extreme values:\n",
        "\n",
        "Let $f(x)=-x^2+4$. We know our max value is 4 at coordinate $(0,4)$. Lets see if we get the same thing using derivatives!\n",
        "\n",
        "1) Find derivative of function\n",
        "\n",
        "$f'(x)=-2x+0=-2x$\n",
        "\n",
        "2} Equal derivative to $0$ and solve for $x$\n",
        "\n",
        "$f'(x)=-2x=0$\n",
        "\n",
        "So, $x=0$\n",
        "\n",
        "3) Plug $x$ value back into original equation to see what the max output is\n",
        "\n",
        "$f(0)=-(0)^2+4=0+4=4$\n",
        "\n",
        "So, as we already knew, we have a max value of $4$ at $x=0$.\n",
        "\n",
        "**Rolle Theorem**: If $f$ is a continuous function with a derivative that exists in the interval $(a,b)$ and if $f(a)=f(b)$, then there must be a value $c$ such that $a < c < b$ that tells us when an extreme value happens ($f'(c)=0$).\n",
        "\n",
        "**Mean Value Theorem**: If $f$ is a continuous function with a derivative that exists in the interval $(a,b)$, there exists $a < c < b$ such that\n",
        "\n",
        "$f'(c) = \\frac{f(b)-f(a)}{b-a}$\n",
        "\n",
        "You can also take the derivative of a derivative (higher-order derivative) as many times ad you want. This can be represented by the following:\n",
        "\n",
        "$f''(x_0)=\\frac{d^2f(x_0)}{dx^2}=\\lim\\limits_{h \\to 0} \\frac{f'(x_0+h)-f'(x_0)}{h}$ (if the limit exists)\n",
        "\n",
        "For example, lets take the second derivative of the function we had above:\n",
        "\n",
        "1st derivative: $f'(x)=-2x$\n",
        "\n",
        "2nd derivative: $f''(x) = -2$\n",
        "\n",
        "YOu can keep going!\n",
        "\n",
        "3rd derivative: $f'''(x)=0$\n",
        "\n",
        "From here on out, your derivative will always be $0$ since the derivative of a constant is $0$."
      ],
      "metadata": {
        "id": "jsvz_CKqC1-W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3.2.2.2: General Case"
      ],
      "metadata": {
        "id": "hZOD-U32LmN0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A **partial derivative**  of $f$ at $x_0$ in respect to $x_i$ can be represented the following way:\n",
        "\n",
        "$\\frac{‚àÇf(x_0)}{\\partial x_i}=\\lim\\limits_{h \\to 0} \\frac{f(x_0+he‚Éó _i)-f(x_0)}{h}$\n",
        "\n",
        "where\n",
        "- We assume the limit exists\n",
        "- $e‚Éó_i \\in ‚Ñù^d$ and it is the $i$-th standard basis vector\n",
        "\n",
        "Find the partial derivative of $f(x,y)=2xy+x^2y+3y$ in respect to $x$. You do this by imagining $y$ to be a constant and continuing to take the derivative normally:\n",
        "\n",
        "$\\frac{‚àÇf(x,y)}{‚àÇx}=f_x(x,y)=2y+2xy+0=2y+2xy$\n",
        "\n",
        "Lets check our work!"
      ],
      "metadata": {
        "id": "mRGLfqkuLrks"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sympy import *  # This includes the importation of Symbol, diff\n",
        "\n",
        "# Specifies which variables are symbols\n",
        "x = symbols('x')\n",
        "\n",
        "# Defines functions\n",
        "f_x = 2*x*y + x**2*y + 3*y\n",
        "\n",
        "# Calculates the partial derivative in respect to x\n",
        "f_x = diff(f_x,x)\n",
        "\n",
        "print(\"Partial Derivative of f(x,y) in respect to x:\")\n",
        "print(f_x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I7KRxFQLJM63",
        "outputId": "d6483a18-5e00-4ec5-afd8-651c3cb361e9"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Partial Derivative of f(x,y) in respect to x:\n",
            "2*x*y + 2*y\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As you can see, we are correct!"
      ],
      "metadata": {
        "id": "8nPhICo2K1h4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Jacobian Matrix**: a matrix that has the partial derivatives of $f‚Éó=(f_1,...f_m)$ as its elements. The following is the Jacobian for $f$:\n",
        "\n",
        "$\\begin{pmatrix}\n",
        "\\frac{‚àÇf_1(x_0)}{\\partial x_1} & \\cdots & \\frac{‚àÇf_1(x_0)}{\\partial x_d} \\\\\n",
        "\\vdots & \\ddots & \\vdots \\\\\n",
        "\\frac{‚àÇf_m(x_0)}{\\partial x_1} & \\cdots & \\frac{‚àÇf_m(x_0)}{\\partial x_d}\n",
        "\\end{pmatrix}$\n",
        "\n",
        "If $f: D \\to ‚Ñù$ is a real-valued function, the Jacobian can be condensed the following way:\n",
        "\n",
        "$J‚Éó_f(x_0)=\\nabla f(x_0)^T$,\n",
        "\n",
        "where\n",
        "\n",
        "$\\nabla f(x_0) = (\\frac{‚àÇf(x_0)}{‚àÇx_1},..., \\frac{‚àÇf(x_0)}{‚àÇx_d} )^T$ is the gradient of $f$ at $x_0$\n",
        "\n",
        ">Note: The gradient equals $\\nabla f = < \\frac{‚àÇf}{‚àÇx} iÃÇ, \\frac{‚àÇf}{‚àÇy}jÃÇ >$. A third element can be added to the vector : $\\frac{‚àÇf}{‚àÇz}kÃÇ$ if needed.\n",
        "\n",
        "The Jacobian of a composition can be derived using the chain rule:\n",
        "\n",
        "$J_{g‚àòf}(x_0)=J_g(f(x_0))J_f(x_0)$\n",
        "\n",
        "where we assume that $f$ is continuously differentiable at $x_0 $and $g$ is continouously differentiable at $f(x_0)$\n",
        "\n",
        "\n",
        "Lets find the Jacobian of the following:\n",
        "\n",
        "$f_1(x,y)= 2xy+x^2y+3y$\n",
        "\n",
        "and\n",
        "\n",
        "$f_2(x,y)= 6xy^2+xy+3x$"
      ],
      "metadata": {
        "id": "wYw8Q1hwJNih"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sympy import *  # This includes the importation of Symbol, diff\n",
        "\n",
        "# Specifies which variables are symbols\n",
        "x, y = symbols('x y')\n",
        "\n",
        "# Defines functions\n",
        "f_1 = 2*x*y + x**2*y + 3*y\n",
        "f_2 = 6*x*y**2 + x*y + 3*x\n",
        "\n",
        "# Calculates partial derivative of f_1 in respect to x\n",
        "partial_f1x = diff(f_1,x)\n",
        "\n",
        "# Calculates partial derivative of f_2 in respect to x\n",
        "partial_f2x = diff(f_2,x)\n",
        "\n",
        "# Calculates partial derivative of f_1 in respect to y\n",
        "partial_f1y = diff(f_1,y)\n",
        "\n",
        "# Calculates partial derivative of f_2 in respect to y\n",
        "partial_f2y = diff(f_2,y)\n",
        "\n",
        "# Makes Jacobian matrix\n",
        "J= Matrix([[partial_f1x, partial_f1y], [partial_f2x, partial_f2y]])\n",
        "\n",
        "print(\"Jacobian Matrix:\")\n",
        "print(J)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t131S0-dJP0x",
        "outputId": "6c53fff3-818b-4a0f-b4ad-b05f8c14f363"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Jacobian Matrix:\n",
            "Matrix([[2*x*y + 2*y, x**2 + 2*x + 3], [6*y**2 + y + 3, 12*x*y + x]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This Jacobian looks like this:\n",
        "\n",
        "$J_f(x,y) =\n",
        "\\begin{bmatrix}\n",
        "\\frac{\\partial f_1}{\\partial x} & \\frac{\\partial f_1}{\\partial y} \\\\\n",
        "\\frac{\\partial f_2}{\\partial x} & \\frac{\\partial f_2}{\\partial y} \\\\\n",
        "\\end{bmatrix} =\n",
        "\\begin{bmatrix}\n",
        "2xy+2y & x^2+2x+3 \\\\\n",
        "6y^2+y+3 & 12xy+x \\\\\n",
        "\\end{bmatrix}$"
      ],
      "metadata": {
        "id": "_GU_u3cdK5jP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3.2.2.3: Further Derivatives"
      ],
      "metadata": {
        "id": "b_DSUugCajIF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The directional derivative of $f$ ($f:D \\to ‚Ñù$, $D \\subseteq ‚Ñù^d$, $x_0 \\in D$, and $v‚Éó \\in ‚Ñù^d$, and $v‚Éó$ is a unit vector such that $v‚Éó \\in ‚Ñù^d$)  in the direction $v‚Éó$ can be represented the following way:\n",
        "\n",
        "$\\frac{‚àÇf(x_0)}{‚àÇv‚Éó}=\\lim\\limits_{h \\to 0}\\frac{f(x_0+hv‚Éó)-f(x_0)}{h}$ (if the limit exists)\n",
        "\n",
        "Taking $v=e_i$ gets the $i$th partial derivative:\n",
        "\n",
        "$\\frac{‚àÇf(x_0)}{‚àÇe_i}=\\lim\\limits_{h \\to 0}\\frac{f(x_0+he_i)-f(x_0)}{h}=\\frac{‚àÇf(x_0)}{‚àÇx_i}$\n",
        "\n",
        ">Note: A general derivative can be expressed in terms of partial derivatives\n",
        "\n",
        "You can aslo find the directional derivative using the gradient (the following terms are the same as the ones mentioned above):\n",
        "\n",
        "$\\frac{‚àÇf(x_0)}{‚àÇv‚Éó}=J_f(x_0)v‚Éó=\\nabla f(x_0)^Tv‚Éó$\n",
        "\n",
        "You can also take higher-order partial derivatives!\n",
        "\n",
        "A **second partial derivatives** can be represented by:\n",
        "\n",
        "$\\frac{‚àÇ^2f(x_0)}{‚àÇx_j‚àÇx_i}=\\lim\\limits_{h \\ to 0}\\frac{‚àÇf(x_0+he_j)/\\partial x_i-‚àÇf(x_0)/‚àÇx_i}{h}$\n",
        "\n",
        "where the terms have the same definition as the ones before\n",
        "\n",
        "**Hessian**: a Jacobian of the gradient $\\nabla f$. It is a matrix for the 2nd partial derivatives of a function. Can be represented like this:\n",
        "\n",
        "$H_f(x_0)=\n",
        "\\begin{pmatrix}\n",
        "\\frac{‚àÇ^2f(x_0)}{\\partial x^2_1} & \\cdots & \\frac{‚àÇ^2f(x_0)}{\\partial x_d‚àÇx_1} \\\\\n",
        "\\vdots & \\ddots & \\vdots \\\\\n",
        "\\frac{‚àÇ^2f(x_0)}{\\partial x_1 \\partial\n",
        "x_d} & \\cdots & \\frac{‚àÇ^2f(x_0)}{\\partial x^2_d}\n",
        "\\end{pmatrix}$\n",
        "\n",
        ">Note: Hessian is symmetric when $f$ is continuously differentiable twice\n",
        "\n",
        "Lets make a Hessian matrix of the following function:\n",
        "\n",
        "$f(x)=2xy+x^2y+3y$"
      ],
      "metadata": {
        "id": "qwfK-IKbanOI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sympy import *  # This includes the importation of Symbol, diff\n",
        "\n",
        "# Specifies which variables are symbols\n",
        "x, y = symbols('x y')\n",
        "\n",
        "# Defines function\n",
        "f = 2*x*y + x**2*y + 3*y\n",
        "\n",
        "# Calculates partial derivative in respect to x\n",
        "partial_x = diff(f,x)\n",
        "\n",
        "# Calculates 2nd partial derivative in respect to x\n",
        "partial_xx = diff(partial_x,x)\n",
        "\n",
        "# Calculates partial derivative in respect to y\n",
        "partial_y = diff(f,y)\n",
        "\n",
        "# Calculates 2nd partial derivative in respect to y\n",
        "partial_yy = diff(partial_y,y)\n",
        "\n",
        "# Calculates partial derivative of partial_x in respects to y\n",
        "partial_xy = diff(partial_x,y)\n",
        "\n",
        "# Calculates partial derivative of partial_y in respects to x\n",
        "partial_yx = diff(partial_y,x)\n",
        "\n",
        "# Creates Hessian matrix\n",
        "H = Matrix([[partial_xx, partial_yx], [partial_xy, partial_yy]])\n",
        "\n",
        "print(\"Hessian Matrix:\")\n",
        "print(H)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f4m2SjmVB_63",
        "outputId": "a916ed63-e3e9-4df2-9713-c8f34dec740d"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hessian Matrix:\n",
            "Matrix([[2*y, 2*x + 2], [2*x + 2, 0]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our Hessian matrix looks like this:\n",
        "\n",
        "$ H_f(x,y)=\n",
        "\\begin{bmatrix}\n",
        "f_{xx}(x,y) & f_{yx}(x,y) \\\\\n",
        "f_{xy}(x,y) & f_{yy}(x,y) \\\\\n",
        "\\end{bmatrix} =\n",
        "\\begin{bmatrix}\n",
        "2y & 2x+2 \\\\\n",
        "2x+2 & 0 \\\\\n",
        "\\end{bmatrix}$"
      ],
      "metadata": {
        "id": "dkJdwy3qHPxm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "#### 3.2.3: Taylor's Theorem"
      ],
      "metadata": {
        "id": "Opav9C-hiKZU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Taylor's Theorem** approximates a differential function near a given point by a polynomial. This can be demonstrated the following way:\n",
        "\n",
        "$f(b)=f(a)+(b-a)f'(a)+\\frac{1}{2}(b-a)^2f''(a)+...+\\frac{(b-a)^{m-1}}{(m-1)!}f^{m-1}(a)+R_m$, where:\n",
        "- $f:D \\to ‚Ñù $\n",
        "- $D ‚äÜ ‚Ñù$\n",
        "- We assume that $f$ is a continuous derivative (in interval $[a,b]$) $m$ times\n",
        "- $R_m = \\frac{(b-a)^m}{(m)!}f^m(a+Œ∏(b-a))$ ($0 < Œ∏ < 1$)\n",
        "\n",
        "\\\\\n",
        "\n",
        "The **multivariate mean value** can be expressed the following way:\n",
        "\n",
        "$f(x)=f(x_0)_\\nabla f(x_0+ùûÅp)^Tp$,\n",
        "\n",
        "where:\n",
        "- $f:D \\to ‚Ñù $\n",
        "- $D ‚äÜ ‚Ñù^d$\n",
        "- $x_0 \\in D$\n",
        "- $ùõø>0$\n",
        "- $B_ùõø(x_0) ‚äÜ D$\n",
        "- We assume that $f$ is continuously differentialble on $B_ùõø(x_0)$\n",
        "- $x \\in B_ùõø(x_0)$\n",
        "- $ùûÅ \\in (0,1)$\n",
        "- $p=x-x_0$\n",
        "\n",
        "For the same conditions/term definitions above (expect that we assume that $f$ is THREE TIMES continuously differentialble on $B_ùõø(x_0)$), a **multivariate Taylor** can be expressed the following way:\n",
        "\n",
        "$f(x)=f(x_0)+\\nabla f(x_0)^Tp+\\frac{1}{2}p^TH_f(x_0)p+ùëÇ(||p||^3)$\n",
        "\n",
        "If $f$ is continuously differentiable TWICE instead, our multivariate Taylor is:\n",
        "\n",
        "$f(x)=f(x_0)+\\nabla f(x_0)^Tp+\\frac{1}{2}p^TH_f(x_0+ùûÅp)p$\n",
        "\n",
        "To use Taylor's Theorem:\n",
        "\n",
        "1) Find gradient of your function\n",
        "\n",
        "2) Construct your Hessian\n",
        "\n",
        "3) Plug in your values into Taylor's Theorem"
      ],
      "metadata": {
        "id": "0pE8w-FCiRUA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\\\\\n",
        "\n",
        "---\n",
        "\n",
        "\\\\\n",
        "## Section 3.3: Unconstrained Optimization"
      ],
      "metadata": {
        "id": "6s9sULtXpsfX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.3.1: Necessary and Sufficient Conditions of Local Minimizers"
      ],
      "metadata": {
        "id": "Ekh4F3IEqrjF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We want to optimize the following:\n",
        "\n",
        "$ \\min\\limits_{x \\in ‚Ñù^d}f(x)$,\n",
        "\n",
        "where $f: ‚Ñù^d \\to ‚Ñù$\n",
        "\n",
        "to find the global minimizer, which is the absolute minimum of $f$.\n",
        "\n",
        "A local minimizer is a point where our slope changes from negative, to zero, to positive. The difference between the global and local minimizer is that there is only one absolute minimum (the lowest point) but there can be many local minimums.\n",
        "\n",
        "A **descent direction** is a vector that points to a local minimum, making it ideal for optimization.\n",
        "\n",
        ">Note: A negative gradient is also a descent direction since it always points\n",
        "in the direction of greatest decrease\n",
        "\n",
        "By the **First-Order Necessary Condition**, if $x_0$ is a local minimizer, $\\nabla f(x_0)=0$ (assuming $f$ is continuously differentiable on $‚Ñù^d$).\n",
        "\n",
        "Assuming the same as we did above, by the **Second-Order Necessary Condition**, if $x_0$ is a local minimizer, the Hessian of function $f$:\n",
        "\n",
        "$H_f(x_0)$\n",
        "\n",
        "is a symmetric $d \\times d$ positive semi-definite matrix. This means that the matrix has non-negative eigenvalues. We know this is the case if $x‚Éó^THx‚Éó ‚â• 0$ for any $x \\in ‚Ñù^d$."
      ],
      "metadata": {
        "id": "SOuNsbuCq4w1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3.3.1.1: Sufficient Conditions for Local Minimizers"
      ],
      "metadata": {
        "id": "mssHJc6T30Iu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Recall, we said that if we have a continuously differentiable function $f$ and calculate for $x_1$ so that $f'(x_1)=0$ and $f''(x_1) ‚â• 0$, we have a local minimum at $x_1$. However, this isn't always the case. Lets take a look at the following function:\n",
        "\n",
        "$f(x)=x^3+5$"
      ],
      "metadata": {
        "id": "BUM2X84j44o4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sympy import Symbol, diff\n",
        "\n",
        "# Specifies which variables are symbols\n",
        "x = symbols('x')\n",
        "\n",
        "# Defines functions\n",
        "f = x**3 + 5\n",
        "\n",
        "# Calculates the derivative in respect to x\n",
        "f_x = diff(f,x)\n",
        "\n",
        "print(f_x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xm0iX25magcU",
        "outputId": "72939fad-f727-44d9-c7d8-5654a56655d6"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3*x**2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we can see, $x=0$ is obviously the solution to $f'(x_1)=0$. So, now let's calculate $f''(x)$."
      ],
      "metadata": {
        "id": "AsPNTB97hKHS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculates the 2nd derivative of f\n",
        "f_xx = diff(f_x,x)\n",
        "print(f_xx)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "82S_n8AvmmXF",
        "outputId": "f0a268eb-a56c-45de-ecda-9aa4af5cce53"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6*x\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we can also see that $f(x_1) ‚â•0$. So, we should have a local minimum at $x_1=0$."
      ],
      "metadata": {
        "id": "G4YyLPPDqQiF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "x = np.linspace(-5,5)\n",
        "f = x**3 + 5\n",
        "\n",
        "plt.plot(x,f)\n",
        "plt.title('f(x)=x^3+5')\n",
        "plt.xlabel('x')\n",
        "plt.ylabel('f(x)')\n",
        "plt.scatter(0,5, color = 'red')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "Kvis7OWNqiek",
        "outputId": "695bb855-656d-48e5-a1b9-b735a00c3403"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As you can see, we do not have a minimum at $x_1=0$. The red dot is the coordinate $(0,5)$.\n",
        "\n",
        "The **Second-Order Sufficient Condition** helps prevent this kind of situation. This condition states that assuming that $f$ is a twice continuously differentiable, if the gradient of $f(x_0)$ is zero, and the Hessian matrix of $f(x_0)$ is positive definite, then we have a local minimizer at $x_0$. In short, these conditions must be met:\n",
        "\n",
        "- $\\nabla f(x_0)=0$\n",
        "- $H_f(x_0)$ is positive definite"
      ],
      "metadata": {
        "id": "udRIT2riu-Pl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.3.2: Convexity and Global Minimizers"
      ],
      "metadata": {
        "id": "7MLP7t5Ow4cz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Convex**: a real-valued function where a line segment between any two distict points on the graph stays above the function. Convexes are useful for optimization problems since they only have one minimum."
      ],
      "metadata": {
        "id": "qd8euW5rxJv9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3.3.2.1: Convex Sets and Function"
      ],
      "metadata": {
        "id": "6T2OBE6R0xRN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convex sets have the following property:\n",
        "\n",
        "$(1-\\alpha)x+\\alpha y \\in D$,\n",
        "\n",
        "where:\n",
        "- $\\forall x,y \\in D: D ‚äÜ ‚Ñù^d$\n",
        "- All $\\alpha \\in [0,1]$\n",
        "\n",
        "**Convex Functions** follow can be expressed the followimg way:\n",
        "\n",
        "$f((1-\\alpha)x+\\alpha y) ‚â§ (1-\\alpha)f(x)+\\alpha f(y)$\n",
        "\n",
        "where all terms have the same definitions specified above.\n",
        "\n",
        ">Note: Affine functions are convex. Affine functions are those that have a linear function plus a translation. Unlike linear functions, affine functions do not have a fixed origin. For example, a linear function is $f(x)=mx$ and an affine function is $f(x)=mx+b$.\n",
        "\n",
        "According to the **First-Order Convexity Condition**, a continuously differentiable function $f$ is convex iff\n",
        "\n",
        "$f(y)‚â•f(x)+\\nabla f(x)^T(y-x)$, $\\forall x,y \\in ‚Ñù^d$\n",
        "\n",
        "Convexity can also be shown with the **second-order convexity condition**, which states that if function $f$ is twice continuously differentiable, it is convex iff the Hessian matrix of $f(x_0)$ is positive definite."
      ],
      "metadata": {
        "id": "RWKFBHqgBiz8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3.3.2.2: Global Minimizer of Convex Functions"
      ],
      "metadata": {
        "id": "-p5ceVlDIXEC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since convex functions only have one minimum, meaning the local minimum and the global minimum are the same, it is a sufficient (and necessary) condition for minimizers to satisfy the following:\n",
        "\n",
        "$\\nabla f(x_0)=0$"
      ],
      "metadata": {
        "id": "_4_mPSRBIl4d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.3: Gradient Descent"
      ],
      "metadata": {
        "id": "UKBH8WE8LW1e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we have mentioned before, we use gradient descent to find local minima of minimization problems with the following form:\n",
        "\n",
        "$\\min\\limits_{x \\in ‚Ñù^d}f(x)$\n",
        "\n",
        "It is most efficient to find the x's such that $\\nabla f(x)=0$ and then see which one of those give you the smallest output."
      ],
      "metadata": {
        "id": "zZ66pUalLaTP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3.3.3.1: Steepest Descent"
      ],
      "metadata": {
        "id": "nxRnatn5OKBp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "By using the gradient, specifically when it is $-\\nabla f$, the steepest descent approach will lead us to find the minimum.\n",
        "\n",
        "The **steepest descent** has the following property:\n",
        "\n",
        "$\\frac{\\partial f(x_0)}{\\partial v ‚Éó} ‚â• \\frac{\\partial f(x_0)}{\\partial v ‚Éó^*}$,\n",
        "\n",
        "where\n",
        "- $v ‚Éó$ is a unit vector\n",
        "- $v^* = -\\frac{\\nabla f(x_0)}{||\\nabla f(x_0)||}$\n",
        "\n",
        "This method requires multiple iterations, each steepest descent bringing you closer and closer to the minimum by following $-\\nabla f$. Since the iterations bring you closer in a step size of $\\alpha_k > 0$, reaching the minimum is not guaranteed."
      ],
      "metadata": {
        "id": "TgI7LPziONIQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\\\\\n",
        "$‚ô°$ **The End** $‚ô°$"
      ],
      "metadata": {
        "id": "zpBC02yPRlun"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JVnfgOeZRpHi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}